{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0.0\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "print(torch.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms\n",
    "import torchvision\n",
    "from torch.autograd import Variable\n",
    "from torch.utils.data import DataLoader\n",
    "import cv2 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "torchvision 用于下载并导入数据集\n",
    "cv2 用于展示数据的图像"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 下载训练集\n",
    "train_dataset = datasets.MNIST(root='./num/',\n",
    "                               train=True,\n",
    "                               transform=transforms.ToTensor(),\n",
    "                               download=True)\n",
    "# 下载测试集\n",
    "test_dataset = datasets.MNIST(root='./num/',\n",
    "                              train=False,\n",
    "                              transform=transforms.ToTensor(),\n",
    "                              download=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "root 用于指定数据集在下载之后的存放路径\n",
    "transform 用于指定导入数据集需要对数据进行那种变化操作\n",
    "train是指定在数据集下载完成后需要载入的那部分数据\n",
    "    设置为 True 则说明载入的是该数据集的训练集部分，设置为 False 则说明载入的是该数据集的测试集部分\n",
    "download 为 True 表示数据集需要程序自动帮你下载, 这样设置并运行后，就会在指定路径中下载 MNIST 数据集，之后就可以使用了。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset 参数用于指定我们载入的数据集名称\n",
    "# batch_size参数设置了每个包中的图片数据个数\n",
    "# 在装载的过程会将数据随机打乱顺序并进打包\n",
    "\n",
    "# 装载训练集,建立一个数据迭代器\n",
    "train_loader = torch.utils.data.DataLoader(dataset=train_dataset,\n",
    "                                           batch_size=32,\n",
    "                                           shuffle=True)\n",
    "# 装载测试集\n",
    "test_loader = torch.utils.data.DataLoader(dataset=test_dataset,\n",
    "                                          batch_size=32,\n",
    "                                          shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "在装载完成后，可以选取其中一个批次的数据进行预览："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 实现单张图片可视化\n",
    "images, labels = next(iter(train_loader))\n",
    "img = torchvision.utils.make_grid(images)\n",
    "\n",
    "img = img.numpy().transpose(1, 2, 0)\n",
    "std = [0.5, 0.5, 0.5]\n",
    "mean = [0.5, 0.5, 0.5]\n",
    "img = img * std + mean\n",
    "print(labels)\n",
    "cv2.imshow('win', img)\n",
    "key_pressed = cv2.waitKey(0)\n",
    "\n",
    "#在以上代码中使用了 iter 和 next 来获取取一个批次的图片数据和其对应的图片标签，\n",
    "#然后使用 torchvision.utils 中的 make_grid 类方法将一个批次的图片构造成网格模式。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "搭建神经网络"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 卷积层使用 torch.nn.Conv2d\n",
    "# 激活层使用 torch.nn.ReLU\n",
    "# 池化层使用 torch.nn.MaxPool2d\n",
    "# 全连接层使用 torch.nn.Linear\n",
    "\n",
    "class LeNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(LeNet, self).__init__()\n",
    "        self.conv1 = nn.Sequential(nn.Conv2d(1, 6, 3, 1, 2), nn.ReLU(),\n",
    "                                   nn.MaxPool2d(2, 2))\n",
    "\n",
    "        self.conv2 = nn.Sequential(nn.Conv2d(6, 16, 5), nn.ReLU(),\n",
    "                                   nn.MaxPool2d(2, 2))\n",
    "\n",
    "        self.fc1 = nn.Sequential(nn.Linear(16 * 5 * 5, 120),\n",
    "                                 nn.BatchNorm1d(120), nn.ReLU())\n",
    "\n",
    "        self.fc2 = nn.Sequential(\n",
    "            nn.Linear(120, 84),\n",
    "            nn.BatchNorm1d(84),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(84, 10))\n",
    "        \t# 最后的结果一定要变为 10，因为数字的选项是 0 ~ 9\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.conv2(x)\n",
    "        x = x.view(x.size()[0], -1)\n",
    "        x = self.fc1(x)\n",
    "        x = self.fc2(x)\n",
    "        return x "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "前向传播内容：\n",
    "首先经过 self.conv1() 和 self.conv1() 进行卷积处理\n",
    "然后进行 x = x.view(x.size()[0], -1)，对参数实现扁平化（便于后面全连接层输入）\n",
    "最后通过 self.fc1() 和 self.fc2() 定义的全连接层进行最后的分类 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "训练模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1,100] loss:1.133\n",
      "[1,200] loss:0.342\n",
      "[1,300] loss:0.201\n",
      "[1,400] loss:0.178\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "batch_size = 64\n",
    "LR = 0.001\n",
    "\n",
    "net = LeNet().to(device)\n",
    "# 损失函数使用交叉熵\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "# 优化函数使用 Adam 自适应优化算法\n",
    "optimizer = optim.Adam( net.parameters(),  lr=LR,)\n",
    "\n",
    "epoch = 1\n",
    "for epoch in range(epoch):\n",
    "    sum_loss = 0.0\n",
    "    for i, data in enumerate(train_loader):\n",
    "        inputs, labels = data\n",
    "        inputs, labels = Variable(inputs).cpu(), Variable(labels).cpu()\n",
    "        optimizer.zero_grad()  #将梯度归零\n",
    "        outputs = net(inputs)  #将数据传入网络进行前向运算\n",
    "        loss = criterion(outputs, labels)  #得到损失函数\n",
    "        loss.backward()  #反向传播\n",
    "        optimizer.step()  #通过梯度做一步参数更新\n",
    "\n",
    "        # print(loss)\n",
    "        sum_loss += loss.item()\n",
    "        if i % 100 == 99:\n",
    "            print('[%d,%d] loss:%.03f' % (epoch + 1, i + 1, sum_loss / 100))\n",
    "            sum_loss = 0.0 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "测试模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "net.eval()  #将模型变换为测试模式\n",
    "correct = 0\n",
    "total = 0\n",
    "for data_test in test_loader:\n",
    "    images, labels = data_test\n",
    "    images, labels = Variable(images).cpu(), Variable(labels).cpu()\n",
    "    output_test = net(images)\n",
    "    _, predicted = torch.max(output_test, 1)\n",
    "    total += labels.size(0)\n",
    "    correct += (predicted == labels).sum()\n",
    "print(\"correct1: \", correct)\n",
    "print(\"Test acc: {0}\".format(correct.item() / len(test_dataset))) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# library\n",
    "# standard library\n",
    "import os\n",
    " \n",
    "# third-party library\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable\n",
    "import torch.utils.data as Data\n",
    "import torchvision\n",
    "import matplotlib.pyplot as plt\n",
    " \n",
    "torch.manual_seed(1)    # reproducible\n",
    " \n",
    "# Hyper Parameters\n",
    "EPOCH = 1               # train the training data n times, to save time, we just train 1 epoch\n",
    "BATCH_SIZE = 50\n",
    "LR = 0.001              # learning rate\n",
    "DOWNLOAD_MNIST = False\n",
    " \n",
    " \n",
    "# Mnist digits dataset\n",
    "if not(os.path.exists('./mnist/')) or not os.listdir('./mnist/'):\n",
    "    # not mnist dir or mnist is empyt dir\n",
    "    DOWNLOAD_MNIST = True\n",
    " \n",
    "train_data = torchvision.datasets.MNIST(\n",
    "    root='./mnist/',\n",
    "    train=True,                                     # this is training data\n",
    "    transform=torchvision.transforms.ToTensor(),    # Converts a PIL.Image or numpy.ndarray to\n",
    "                                                    # torch.FloatTensor of shape (C x H x W) and normalize in the range [0.0, 1.0]\n",
    "    download=DOWNLOAD_MNIST,\n",
    ")\n",
    " \n",
    "# plot one example\n",
    "print(train_data.train_data.size())                 # (60000, 28, 28)\n",
    "print(train_data.train_labels.size())               # (60000)\n",
    "plt.imshow(train_data.train_data[50].numpy(), cmap='gray')\n",
    "plt.title('%i' % train_data.train_labels[1])\n",
    "plt.show()\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
