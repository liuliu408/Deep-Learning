{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 网络爬取百度图片搜索中的图片"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import urllib.request\n",
    "import re\n",
    "import requests\n",
    "import time\n",
    "import logging\n",
    "\n",
    "LocalDay = time.strftime(\"%Y-%m-%d\")\n",
    "logFile = r'D:\\python\\{0}.log'.format(LocalDay)\n",
    "logging.basicConfig(level=logging.DEBUG,\n",
    "                 format='%(asctime)s %(filename)s[line:%(lineno)d] %(levelname)s %(message)s',\n",
    "                 datefmt='%a, %d %b %Y %H:%M:%S',\n",
    "                 filename=logFile,\n",
    "                 filemode='a+')\n",
    "\n",
    "console = logging.StreamHandler()\n",
    "console.setLevel(logging.INFO)\n",
    "formatter = logging.Formatter('%(name)-12s: %(levelname)-8s %(message)s')\n",
    "console.setFormatter(formatter)\n",
    "logging.getLogger('').addHandler(console)\n",
    "\n",
    "def getDatas(keyword, pages):\n",
    "    params = []\n",
    "    for i in range(30, 30 * pages + 30, 30):\n",
    "        params.append({\n",
    "            'tn': 'resultjson_com',\n",
    "            'ipn': 'rj',\n",
    "            'ct': 201326592,\n",
    "            'is': '',\n",
    "            'fp': 'result',\n",
    "            'queryWord': keyword,\n",
    "            'cl': 2,\n",
    "            'lm': -1,\n",
    "            'ie': 'utf-8',\n",
    "            'oe': 'utf-8',\n",
    "            'adpicid': '',\n",
    "            'st': -1,\n",
    "            'z': '',\n",
    "            'ic': 0,\n",
    "            'word': keyword,\n",
    "            's': '',\n",
    "            'se': '',\n",
    "            'tab': '',\n",
    "            'width': '',\n",
    "            'height': '',\n",
    "            'face': 0,\n",
    "            'istype': 2,\n",
    "            'qc': '',\n",
    "            'nc': 1,\n",
    "            'fr': '',\n",
    "            'pn': i,\n",
    "            'rn': 30,\n",
    "            'gsm': '1e',\n",
    "            '1526377465547': ''\n",
    "        })\n",
    "    url = 'https://image.baidu.com/search/index'\n",
    "    urls = []\n",
    "    for i in params:\n",
    "        urls.append(requests.get(url, params=i).json().get('data'))\n",
    "    return urls\n",
    "\n",
    "\n",
    "def getImg(datalist, path):\n",
    "    x = 0\n",
    "    for list in datalist:\n",
    "        for i in list:\n",
    "            if i.get('thumbURL') != None:\n",
    "                logging.info('正在下载：%s' % i.get('thumbURL'))\n",
    "                urllib.request.urlretrieve(i.get('thumbURL'), path + '%d.jpg' % x)\n",
    "                x += 1\n",
    "            else:\n",
    "                logging.info('当前轮次已经下载完成')\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    queryKeyword = \"路标\"          #查询关键字\n",
    "    pages = 10                     #下载页数\n",
    "    totalPics = pages*30\n",
    "    logging.info('开始下载%s的图片,预计下载图片%d张'%(queryKeyword,totalPics))\n",
    "    datalist = getDatas(queryKeyword, pages)\n",
    "    \n",
    "    savepath=\"D://python//路标//\"  #保存图片路径！\n",
    "    if not os.path.exists(savepath):\n",
    "        os.makedirs(savepath)\n",
    "        \n",
    "    getImg(datalist, os.path.join(savepath, 'img'))  #图片名字\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "文件已存在\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from urllib.request import urlretrieve\n",
    "import requests\n",
    "\n",
    "savepath=\"D://python//111//\"  #保存图片路径！\n",
    "if not os.path.exists(savepath):\n",
    "    os.makedirs(savepath)\n",
    "\n",
    "import requests\n",
    "import os\n",
    "url=\"https://www.yuoimg.com/u/20191129/09140963.jpg\"\n",
    "root=savepath   #根目录\n",
    "path=root+url.split('/')[-1] #根目录加上url中以反斜杠分割的最后一部分，即可以以图片原来的名字存储在本地\n",
    "try:\n",
    "    if not os.path.exists(root):#判断当前根目录是否存在\n",
    "        os.mkdir(root)          #创建根目录\n",
    "    if not os.path.exists(path):#判断文件是否存在\n",
    "        r=requests.get(url)\n",
    "        with open(path,'wb')as f:\n",
    "            f.write(r.content)\n",
    "            f.close()\n",
    "            print(\"文件保存成功\")\n",
    "    else:\n",
    "        print(\"文件已存在\")\n",
    "except:\n",
    "    print(\"爬取失败\")    \n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#通过python 来爬取网站内所有的图片到本地  \n",
    "#爬取网址: https://www.mzitu.com/xinggan/page/1/\n",
    "#https://blog.csdn.net/qq_33958297/article/details/89388556"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    " \n",
    "import requests\n",
    "import os\n",
    "from lxml import etree\n",
    "from threading import *\n",
    "from time import sleep\n",
    " \n",
    "nMaxThread = 3  #这里设置需要开启几条线程\n",
    "ThreadLock = BoundedSemaphore(nMaxThread)\n",
    " \n",
    "gHeads = {\n",
    "    \"User-Agent\":\"Mozilla/5.0 (Windows NT 6.1; WOW64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/55.0.2883.87 Safari/537.36\",\n",
    "}\n",
    " \n",
    "class Meizitu(Thread):\n",
    "    def __init__(self,url,title):\n",
    "        Thread.__init__(self)\n",
    "        self.url = url  #这里的url在后面的referer中需要使用\n",
    "        self.title = title\n",
    " \n",
    "    def run(self):\n",
    "        try:\n",
    "            PhotoUrl,Page = self.GetPhotoUrlAndPageNum()\n",
    "            if PhotoUrl and Page > 0:\n",
    "                self.SavePhoto(PhotoUrl,Page)\n",
    "        finally:\n",
    "            ThreadLock.release()\n",
    " \n",
    "    def GetPhotoUrlAndPageNum(self):\n",
    "        html = requests.get(self.url,headers=gHeads)\n",
    "        if html.status_code == 200:\n",
    "            xmlContent = etree.HTML(html.text)\n",
    "            PhotoUrl = xmlContent.xpath(\"//div[@class='main-image']/p/a/img/@src\")[0][:-6] #01.jpg  正好是-6\n",
    "            PageNum = xmlContent.xpath(\"//div[@class='pagenavi']/a[5]/span/text()\")[0]\n",
    "            return PhotoUrl,int(PageNum)\n",
    "        else:\n",
    "            return None,None\n",
    " \n",
    "    def SavePhoto(self,url,page):\n",
    "        savePath = \"./photo/%s\" % self.title\n",
    "        if not os.path.exists(savePath):\n",
    "            os.makedirs(savePath)\n",
    "        for i in range(page):\n",
    "            heads = {\n",
    "                \"User-Agent\":\"Mozilla/5.0 (Windows NT 6.1; WOW64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/55.0.2883.87 Safari/537.36\",\n",
    "                \"Referer\": \"%s/%d\" %(self.url,i+1),\n",
    "                \"Accept\": \"image/webp,image/apng,image/*,*/*;q=0.8\"\n",
    "            }\n",
    "            j = 0\n",
    "            while j<5:\n",
    "                print (u\"Download : %s/%d.jpg\" % (self.title, i + 1))\n",
    "                html = requests.get(\"%s%02d.jpg\"%(url,i+1),headers=heads)\n",
    "                if html.status_code == 200:\n",
    "                    with open(savePath + \"/%d.jpg\"%(i+1),\"wb\") as f:\n",
    "                        f.write(html.content)\n",
    "                    break\n",
    "                elif html.status_code == 404:\n",
    "                    j+=1\n",
    "                    sleep(0.05)\n",
    "                    continue\n",
    "                else:\n",
    "                    return None\n",
    " \n",
    " \n",
    "def main():\n",
    "    while True:\n",
    "        try:\n",
    "            nNum = int(input(u\"请输入要下载几页: \"))\n",
    "            if nNum>0:\n",
    "                break\n",
    "        except ValueError:\n",
    "            print(u\"请输入数字。\")\n",
    "            continue\n",
    "    for i in range(nNum):\n",
    "        url = \"https://www.mzitu.com/japan/page/%d/\"%(i+1)\n",
    "        html = requests.get(url,headers=gHeads)\n",
    "        if html.status_code == 200:\n",
    "            xmlContent = etree.HTML(html.content)\n",
    "            hrefList = xmlContent.xpath(\"//ul[@id='pins']/li/a/@href\")\n",
    "            titleList = xmlContent.xpath(\"//ul[@id='pins']/li/a/img/@alt\")\n",
    "            for i in range(len(hrefList)):\n",
    "                ThreadLock.acquire()\n",
    "                t = Meizitu(hrefList[i],titleList[i])\n",
    "                t.start()\n",
    " \n",
    " \n",
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Python 爬虫系列教程一爬取批量百度图片\n",
    "https://blog.csdn.net/qq_40774175/article/details/81273198"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import requests\n",
    "from urllib import error\n",
    "from bs4 import BeautifulSoup\n",
    "import os\n",
    " \n",
    "num = 0\n",
    "numPicture = 0\n",
    "file = ''\n",
    "List = []\n",
    " \n",
    " \n",
    "def Find(url):\n",
    "    global List\n",
    "    print('正在检测图片总数，请稍等.....')\n",
    "    t = 0\n",
    "    i = 1\n",
    "    s = 0\n",
    "    while t < 1000:\n",
    "        Url = url + str(t)\n",
    "        try:\n",
    "            Result = requests.get(Url, timeout=7)\n",
    "        except BaseException:\n",
    "            t = t + 60\n",
    "            continue\n",
    "        else:\n",
    "            result = Result.text\n",
    "            pic_url = re.findall('\"objURL\":\"(.*?)\",', result, re.S)  # 先利用正则表达式找到图片url\n",
    "            s += len(pic_url)\n",
    "            if len(pic_url) == 0:\n",
    "                break\n",
    "            else:\n",
    "                List.append(pic_url)\n",
    "                t = t + 60\n",
    "    return s\n",
    " \n",
    " \n",
    "def recommend(url):\n",
    "    Re = []\n",
    "    try:\n",
    "        html = requests.get(url)\n",
    "    except error.HTTPError as e:\n",
    "        return\n",
    "    else:\n",
    "        html.encoding = 'utf-8'\n",
    "        bsObj = BeautifulSoup(html.text, 'html.parser')\n",
    "        div = bsObj.find('div', id='topRS')\n",
    "        if div is not None:\n",
    "            listA = div.findAll('a')\n",
    "            for i in listA:\n",
    "                if i is not None:\n",
    "                    Re.append(i.get_text())\n",
    "        return Re\n",
    " \n",
    " \n",
    "def dowmloadPicture(html, keyword):\n",
    "    global num\n",
    "    # t =0\n",
    "    pic_url = re.findall('\"objURL\":\"(.*?)\",', html, re.S)  # 先利用正则表达式找到图片url\n",
    "    print('找到关键词:' + keyword + '的图片，即将开始下载图片...')\n",
    "    for each in pic_url:\n",
    "        print('正在下载第' + str(num + 1) + '张图片，图片地址:' + str(each))\n",
    "        try:\n",
    "            if each is not None:\n",
    "                pic = requests.get(each, timeout=7)\n",
    "            else:\n",
    "                continue\n",
    "        except BaseException:\n",
    "            print('错误，当前图片无法下载')\n",
    "            continue\n",
    "        else:\n",
    "            string = file + r'\\\\' + keyword + '_' + str(num) + '.jpg'\n",
    "            fp = open(string, 'wb')\n",
    "            fp.write(pic.content)\n",
    "            fp.close()\n",
    "            num += 1\n",
    "        if num >= numPicture:\n",
    "            return\n",
    " \n",
    " \n",
    "if __name__ == '__main__':  # 主函数入口\n",
    "    word = input(\"请输入搜索关键词(可以是人名，地名等): \")\n",
    "    #add = 'http://image.baidu.com/search/flip?tn=baiduimage&ie=utf-8&word=%E5%BC%A0%E5%A4%A9%E7%88%B1&pn=120'\n",
    "    url = 'http://image.baidu.com/search/flip?tn=baiduimage&ie=utf-8&word=' + word + '&pn='\n",
    "    tot = Find(url)\n",
    "    Recommend = recommend(url)  # 记录相关推荐\n",
    "    print('经过检测%s类图片共有%d张' % (word, tot))\n",
    "    numPicture = int(input('请输入想要下载的图片数量 '))\n",
    "    file = input('请建立一个存储图片的文件夹，输入文件夹名称即可')\n",
    "    y = os.path.exists(file)\n",
    "    if y == 1:\n",
    "        print('该文件已存在，请重新输入')\n",
    "        file = input('请建立一个存储图片的文件夹，)输入文件夹名称即可')\n",
    "        os.mkdir(file)\n",
    "    else:\n",
    "        os.mkdir(file)\n",
    "    t = 0\n",
    "    tmp = url\n",
    "    while t < numPicture:\n",
    "        try:\n",
    "            url = tmp + str(t)\n",
    "            result = requests.get(url, timeout=10)\n",
    "            print(url)\n",
    "        except error.HTTPError as e:\n",
    "            print('网络错误，请调整网络后重试')\n",
    "            t = t+60\n",
    "        else:\n",
    "            dowmloadPicture(result.text, word)\n",
    "            t = t + 60\n",
    " \n",
    "    print('当前搜索结束，感谢使用')\n",
    "    print('猜你喜欢')\n",
    "    for re in Recommend:\n",
    "        print(re, end='  ')\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
